{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdcd052-cf07-431d-8a3d-dde0881cb419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e29b4e8d-a841-4fb3-ad7a-e9cbc24f2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d021fb32-b9da-442b-a2fd-2c646d7bce5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e4c5d6-4d17-4903-9cda-e5cc1d01736a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2ab626-7477-4821-9947-7d5a65df3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentiment']=pd.cut(data['Score'], bins=[0,2,3,5], labels=['Negative', 'Nuetral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a5d1279-3146-4ae3-a7cd-523b4caeae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text=str(text).lower()\n",
    "     # Remove text within square brackets\n",
    "    text=re.sub('\\[.*?\\]','',text)\n",
    "    # Remove URLs\n",
    "    text=re.sub('https?://\\S+|www\\.\\S+','',text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    #  Removing Punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Replace newline characters with spaces\n",
    "    text = re.sub('\\n', '', text)\n",
    "    # Remove words containing digits\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "     # Tokenize the text and remove stopwords\n",
    "    text = [word for word in text.split(' ') if word not in stopwords]\n",
    "    text=\" \".join(text)\n",
    "    # Stem the remaining words\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    # Join the cleaned and stemmed words back into a string\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e95470ef-1d83-414c-98ac-b868ed4f8b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         bought sever vital can          product arriv label jumbo salt          confect around          look secret ingredi          great taffi great price  wid                                                            great sesam chickenthi good     im disappoint flavor     star small give      best treat train     satisfi product advertisednam text length  dtype object'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf79b9ab-dbff-4aae-8320-3402a5897698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought sever vital can dog food product found ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arriv label jumbo salt peanutsth peanu...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confect around centuri  light pillowi citrus g...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>look secret ingredi robitussin believ found  g...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffi great price  wide assort yummi taf...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>great sesam chickenthi good better restur eate...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>im disappoint flavor chocol note especi weak m...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>star small give  one train session  tri train ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>best treat train reward dog good groom  lower ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>satisfi product advertis use cereal raw vinega...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text     Score\n",
       "0       bought sever vital can dog food product found ...  Positive\n",
       "1       product arriv label jumbo salt peanutsth peanu...  Negative\n",
       "2       confect around centuri  light pillowi citrus g...  Positive\n",
       "3       look secret ingredi robitussin believ found  g...  Negative\n",
       "4       great taffi great price  wide assort yummi taf...  Positive\n",
       "...                                                   ...       ...\n",
       "568449  great sesam chickenthi good better restur eate...  Positive\n",
       "568450  im disappoint flavor chocol note especi weak m...  Negative\n",
       "568451  star small give  one train session  tri train ...  Positive\n",
       "568452  best treat train reward dog good groom  lower ...  Positive\n",
       "568453  satisfi product advertis use cereal raw vinega...  Positive\n",
       "\n",
       "[568454 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned=pd.DataFrame()\n",
    "data_cleaned['Text']=data[\"Text\"].apply(clean)\n",
    "data_cleaned['Score']=data['Sentiment']\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631b6d62-8adf-4b73-993b-c89228402590",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data_cleaned['Text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3094d32-2383-4ebf-86a7-a59bc7ac16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=5000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(text)\n",
    "# tokenizes the input text data into sequences of integer indices\n",
    "sequences = tokenizer.texts_to_sequences(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "812043c1-9cc8-4f26-a2b0-8bfc33cb58d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sequences\n",
    "x= pad_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fa7a987-5ae9-40e5-9d47-0539931a961f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  817,    7,   38],\n",
       "       [   0,    0,    0, ..., 2735,    7, 4154],\n",
       "       [   0,    0,    0, ...,  377, 1636, 1266],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    1,   19,   13],\n",
       "       [   0,    0,    0, ...,  733, 1103,   40],\n",
       "       [   0,    0,    0, ...,  705,  594, 1688]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd6244-44db-49a9-aa86-549cb4a16f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_cleaned['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8225ed-ac8f-4e36-88e5-27c264294d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0fb892a-e9d6-4257-b9a1-235e1cf394a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for sentence in text:\n",
    "    tokens.extend(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3eb2f58-db3a-4b02-b2c7-37f968fa9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "for token in tokens:\n",
    "    if token in word_count:\n",
    "        word_count[token] += 1\n",
    "    else:\n",
    "        word_count[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476518ce-a4c2-4dc6-88ca-bdc549c860e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(data_cleaned['Score']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48996c8-795a-42ec-b0b2-a6bed6469ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89127392-cc9a-4631-a97a-11f5f27528e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, output_dim=50),\n",
    "    tf.keras.layers.LSTM(50),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fabb4af-9225-44ea-8249-3971662f9f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71f783f1-7e80-4100-86fe-165a19071f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464bf9e8-792f-48ee-a287-6668eb8a9793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,epochs = 15,batch_size=100,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ca9a0d-7da0-44dc-bf1f-08a19fcad705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 1682)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e7543e-451c-4bb8-9f00-c1a55715bd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
